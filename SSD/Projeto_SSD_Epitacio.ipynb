{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto de Sinais e Sistemas Dinâmicos\n",
    "### Detecção de faces utilizando a base ORL Faces\n",
    "Aluno: Epitácio Pessoa de Brito Neto\n",
    "\n",
    "Professor: Derzu Omaia\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "Este é o projeto da disciplina de Sinais e Sistemas Dinâmicos do curso de Engenharia da Computação - UFPB, ministrada pelo professor Derzu Omaia. O intuito deste projeto é a obtenção de conhecimentos de aplicação de assuntos da disciplina em nossa área, neste caso, temos o auxilio da transformada de Fourier para reconhecimento facial, utilizando a base de dados disponibilizada pelo professor, e utilizaremos como apoio os nossos conhecimentos de programação, análise de pré-processamento de dados e Inteligência Artificial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabeçalho dos includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error\n",
    "from scipy.spatial import distance\n",
    "import cmath\n",
    "from numpy import linalg as LA\n",
    "import scipy.spatial as spt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Declaração de funções de auxilio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente definimos algumas funções para auxiliar futuramente na análise. A primeira delas é para diminuir/aumentar a resolução para fazermos a análise de cada uma delas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cortar_imagem(n, imagem):    \n",
    "    largura_da_imagem = 92\n",
    "    altura_da_imagem = 112\n",
    "    \n",
    "    x = altura_da_imagem//2\n",
    "    y = largura_da_imagem//2\n",
    "    r = n//2\n",
    "    \n",
    "    impar = 0\n",
    "    if n % 2 != 0:\n",
    "        impar = -1\n",
    "    \n",
    "    return imagem[x-r+impar:x+r,y-r+impar:y+r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As próximas funções são, basicamente, o algoritmo do KNN, o suporte das bibliotecas como SKLearn foi tentada para fazer, mas se tornou mais prático fazer o projeto a partir do próprio algoritmo. Nesta primeira função, utilizamos dela para resolver 4 dos 5 casos de teste que foi requisitado: análise apenas da parte real, apenas da parte imaginária, a soma do real com a imaginária, e um 'merge' do real com imaginário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(subjects, dataframe, mode):\n",
    "    \n",
    "    nearest_indexes = []\n",
    "    nearest_labels = []\n",
    "    \n",
    "    for i, labeless_image in enumerate(subjects):\n",
    "        \n",
    "        nearest = math.inf\n",
    "        nearest_index = 0\n",
    "        \n",
    "        for j, labeled_image in enumerate(dataframe):\n",
    "            \n",
    "            if mode == 'r':\n",
    "                mse = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "            if mode == 'i':\n",
    "                mse = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "            if mode == 'ri':\n",
    "                mse_real = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "                mse_imag = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "                mse = mse_real + mse_imag\n",
    "            if mode == 'rim':\n",
    "                labeled_image_aux = labeled_image\n",
    "                labeled_image_aux = eucld(labeled_image_aux.real, labeled_image_aux.imag)\n",
    "                labeless_image = eucld(labeless_image.real, labeless_image.imag)\n",
    "                mse = mean_squared_error(labeled_image_aux, labeless_image)\n",
    "            if mode == 'rimul':\n",
    "                mse_real = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "                mse_imag = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "                mse = np.dot(mse_real, mse_imag)\n",
    "            if mse < nearest:\n",
    "                nearest = mse\n",
    "                nearest_index = j\n",
    "        nearest_indexes.append(nearest_index)\n",
    "        nearest_labels.append(labels[nearest_index])\n",
    "        \n",
    "    return nearest_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O KNN2 foi feito especificamente para resolver o caso de teste 'Real e Imaginario', já que mudaria a estrutura que foi feita para resolver os outros 4 casos de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn2(subjects, dataframe):\n",
    "    \n",
    "    nearest_indexes = []\n",
    "    nearest_labels = []\n",
    "    \n",
    "    for i, labeless_image in enumerate(subjects):\n",
    "        \n",
    "        nearest = math.inf\n",
    "        nearest_index = 0\n",
    "        \n",
    "        for j, labeled_image in enumerate(dataframe):\n",
    "            mse_real_imag = mean_squared_error(labeled_image.real, labeless_image.imag)\n",
    "            mse_imag_real = mean_squared_error(labeled_image.imag, labeless_image.real)\n",
    "            mse_real = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "            mse_imag = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "\n",
    "            distance_list = [mse_real_imag, mse_imag_real, mse_real, mse_imag]\n",
    "            mse = sorted(distance_list)[0]\n",
    "            if mse < nearest:\n",
    "                nearest = mse\n",
    "                nearest_index = j\n",
    "        nearest_indexes.append(nearest_index)\n",
    "        nearest_labels.append(labels[nearest_index])\n",
    "        \n",
    "    return nearest_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi tentado criar uma função para distancia euclidiana para matrizes Numpy, mas não foi conseguido êxito, o que resultou na falha ao fazer o teste de 'merge'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucld(subject, dataframe):\n",
    "    V = spt.distance.pdist(subject.T, 'sqeuclidean')\n",
    "    return spt.distance.squareform(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui armazenamos e transformamos as imagens em Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_de_pessoas = 40\n",
    "fotos_pessoas = 10\n",
    "\n",
    "fotos_das_pessoas = list() \n",
    "primeira_foto_das_pessoas = list() \n",
    "fotos_de_cada_pessoa = list()\n",
    "\n",
    "for i in range(1, quantidade_de_pessoas+1):\n",
    "    for j in range(1, fotos_pessoas+1):\n",
    "        fotos_das_pessoas.append(np.array(cv2.imread(f'.\\orl_faces\\s{i}\\{j}.pgm',0)))\n",
    "        if j == 1:\n",
    "            primeira_foto_das_pessoas.append(np.array(cv2.imread(f'.\\orl_faces\\s{i}\\{j}.pgm',0)))\n",
    "        if j != 1:\n",
    "            fotos_de_cada_pessoa.append(np.array(cv2.imread(f'.\\orl_faces\\s{i}\\{j}.pgm',0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho do dataframe bate com o esperado, dado as informações contidas na descrição do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho: 360\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho: {len(fotos_de_cada_pessoa)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é feita a transformada de Fourier dos arrays que fizemos anteriormente, em seguida fazemos um shift para centralizar o que conseguimos transformar, para facilitar a manipulação durante a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pessoas_fft = [np.fft.fft2(pessoa) for pessoa in fotos_de_cada_pessoa]\n",
    "\n",
    "pessoa_fft = [np.fft.fft2(pessoa) for pessoa in primeira_foto_das_pessoas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pessoas_fft_shift = [np.fft.fftshift(pessoa) for pessoa in pessoas_fft]\n",
    "\n",
    "pessoa_fft_shift = [np.fft.fftshift(pessoa) for pessoa in pessoa_fft]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui ajustamos a resolução das imagens originais, os testes serão feitos com valores de resolução entre [2-30], intervalo que considerei satisfatível, dado os valores de acurácia que vão ser vistos em breve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensao = 30\n",
    "corte = []\n",
    "corte_unico = []\n",
    "for imagem in pessoas_fft_shift:\n",
    "    corte.append(np.array(cortar_imagem(dimensao, imagem)).flatten())\n",
    "      \n",
    "for imagem in pessoa_fft_shift:\n",
    "    corte_unico.append(np.array(cortar_imagem(dimensao, imagem)).flatten())\n",
    "    \n",
    "X = np.array(corte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(40) for j in range(9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento\n",
    "### 4.1 Caso de teste: Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "dimensoes = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real = []\n",
    "\n",
    "print(\"Carregando\")\n",
    "for dimensao in dimensoes:\n",
    "    subject = [cortar_imagem(dimensao, i) for i in pessoa_fft_shift]\n",
    "    dataframe = [cortar_imagem(dimensao, i) for i in pessoas_fft_shift]\n",
    "    labels_predict_real.append(knn(subject, dataframe, 'r'))\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para a resolução  2: 0.9\n",
      "Acurácia para a resolução  3: 0.975\n",
      "Acurácia para a resolução  4: 0.975\n",
      "Acurácia para a resolução  5: 0.975\n",
      "Acurácia para a resolução  6: 0.975\n",
      "Acurácia para a resolução  7: 0.975\n",
      "Acurácia para a resolução  8: 1.0\n",
      "Acurácia para a resolução  9: 1.0\n",
      "Acurácia para a resolução 10: 1.0\n",
      "Acurácia para a resolução 11: 1.0\n",
      "Acurácia para a resolução 12: 1.0\n",
      "Acurácia para a resolução 13: 1.0\n",
      "Acurácia para a resolução 14: 1.0\n",
      "Acurácia para a resolução 15: 1.0\n",
      "Acurácia para a resolução 16: 1.0\n",
      "Acurácia para a resolução 17: 1.0\n",
      "Acurácia para a resolução 18: 1.0\n",
      "Acurácia para a resolução 19: 1.0\n",
      "Acurácia para a resolução 20: 1.0\n",
      "Acurácia para a resolução 21: 1.0\n",
      "Acurácia para a resolução 22: 1.0\n",
      "Acurácia para a resolução 23: 1.0\n",
      "Acurácia para a resolução 24: 1.0\n",
      "Acurácia para a resolução 25: 1.0\n",
      "Acurácia para a resolução 26: 1.0\n",
      "Acurácia para a resolução 27: 1.0\n",
      "Acurácia para a resolução 28: 1.0\n",
      "Acurácia para a resolução 29: 1.0\n",
      "Acurácia para a resolução 30: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real):\n",
    "    print(\"Acurácia para a resolução {:2}: {}\" .format((i+2), accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Caso de teste: Imaginario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "dimensoes = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_imag = []\n",
    "\n",
    "print(\"Carregando\")\n",
    "for dimensao in dimensoes:\n",
    "    subject = [cortar_imagem(dimensao, i) for i in pessoa_fft_shift]\n",
    "    dataframe = [cortar_imagem(dimensao, i) for i in pessoas_fft_shift]\n",
    "    labels_predict_imag.append(knn(subject, dataframe, 'i'))\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para a resolução  2: 0.5\n",
      "Acurácia para a resolução  3: 0.875\n",
      "Acurácia para a resolução  4: 0.925\n",
      "Acurácia para a resolução  5: 0.925\n",
      "Acurácia para a resolução  6: 0.925\n",
      "Acurácia para a resolução  7: 0.95\n",
      "Acurácia para a resolução  8: 0.95\n",
      "Acurácia para a resolução  9: 0.95\n",
      "Acurácia para a resolução 10: 0.95\n",
      "Acurácia para a resolução 11: 0.95\n",
      "Acurácia para a resolução 12: 0.95\n",
      "Acurácia para a resolução 13: 0.95\n",
      "Acurácia para a resolução 14: 0.95\n",
      "Acurácia para a resolução 15: 0.95\n",
      "Acurácia para a resolução 16: 0.95\n",
      "Acurácia para a resolução 17: 0.95\n",
      "Acurácia para a resolução 18: 0.95\n",
      "Acurácia para a resolução 19: 0.95\n",
      "Acurácia para a resolução 20: 0.95\n",
      "Acurácia para a resolução 21: 0.95\n",
      "Acurácia para a resolução 22: 0.95\n",
      "Acurácia para a resolução 23: 0.95\n",
      "Acurácia para a resolução 24: 0.95\n",
      "Acurácia para a resolução 25: 0.95\n",
      "Acurácia para a resolução 26: 0.95\n",
      "Acurácia para a resolução 27: 0.95\n",
      "Acurácia para a resolução 28: 0.95\n",
      "Acurácia para a resolução 29: 0.95\n",
      "Acurácia para a resolução 30: 0.95\n"
     ]
    }
   ],
   "source": [
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_imag):\n",
    "    print(\"Acurácia para a resolução {:2}: {}\" .format((i+2), accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Caso de teste: Real + Imaginario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "dimensoes = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real_imag = []\n",
    "\n",
    "print(\"Carregando\")\n",
    "for dimensao in dimensoes:\n",
    "    subject = [cortar_imagem(dimensao, i) for i in pessoa_fft_shift]\n",
    "    dataframe = [cortar_imagem(dimensao, i) for i in pessoas_fft_shift]\n",
    "    labels_predict_real_imag.append(knn(subject, dataframe, 'ri'))\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para a resolução  2: 0.975\n",
      "Acurácia para a resolução  3: 0.975\n",
      "Acurácia para a resolução  4: 0.975\n",
      "Acurácia para a resolução  5: 0.95\n",
      "Acurácia para a resolução  6: 0.95\n",
      "Acurácia para a resolução  7: 0.95\n",
      "Acurácia para a resolução  8: 0.95\n",
      "Acurácia para a resolução  9: 0.95\n",
      "Acurácia para a resolução 10: 0.95\n",
      "Acurácia para a resolução 11: 0.95\n",
      "Acurácia para a resolução 12: 0.95\n",
      "Acurácia para a resolução 13: 0.95\n",
      "Acurácia para a resolução 14: 0.95\n",
      "Acurácia para a resolução 15: 0.95\n",
      "Acurácia para a resolução 16: 0.95\n",
      "Acurácia para a resolução 17: 0.95\n",
      "Acurácia para a resolução 18: 0.95\n",
      "Acurácia para a resolução 19: 0.95\n",
      "Acurácia para a resolução 20: 0.95\n",
      "Acurácia para a resolução 21: 0.95\n",
      "Acurácia para a resolução 22: 0.95\n",
      "Acurácia para a resolução 23: 0.95\n",
      "Acurácia para a resolução 24: 0.95\n",
      "Acurácia para a resolução 25: 0.975\n",
      "Acurácia para a resolução 26: 0.975\n",
      "Acurácia para a resolução 27: 0.975\n",
      "Acurácia para a resolução 28: 0.975\n",
      "Acurácia para a resolução 29: 0.975\n",
      "Acurácia para a resolução 30: 0.975\n"
     ]
    }
   ],
   "source": [
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real_imag):\n",
    "    print(\"Acurácia para a resolução {:2}: {}\" .format((i+2), accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Caso de teste: Real e Imaginario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando...\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "dimensoes = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real_e_imag = []\n",
    "\n",
    "print(\"Carregando...\")\n",
    "for dimensao in dimensoes:\n",
    "    subject = [cortar_imagem(dimensao, i) for i in pessoa_fft_shift]\n",
    "    dataframe = [cortar_imagem(dimensao, i) for i in pessoas_fft_shift]\n",
    "    labels_predict_real_e_imag.append(knn2(subject, dataframe))\n",
    "    \n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para a resolução  2: 0.575\n",
      "Acurácia para a resolução  3: 0.9\n",
      "Acurácia para a resolução  4: 0.95\n",
      "Acurácia para a resolução  5: 0.95\n",
      "Acurácia para a resolução  6: 0.95\n",
      "Acurácia para a resolução  7: 0.95\n",
      "Acurácia para a resolução  8: 0.95\n",
      "Acurácia para a resolução  9: 0.95\n",
      "Acurácia para a resolução 10: 0.95\n",
      "Acurácia para a resolução 11: 0.95\n",
      "Acurácia para a resolução 12: 0.975\n",
      "Acurácia para a resolução 13: 0.975\n",
      "Acurácia para a resolução 14: 0.975\n",
      "Acurácia para a resolução 15: 0.975\n",
      "Acurácia para a resolução 16: 0.975\n",
      "Acurácia para a resolução 17: 0.975\n",
      "Acurácia para a resolução 18: 0.975\n",
      "Acurácia para a resolução 19: 0.975\n",
      "Acurácia para a resolução 20: 0.975\n",
      "Acurácia para a resolução 21: 0.975\n",
      "Acurácia para a resolução 22: 0.975\n",
      "Acurácia para a resolução 23: 0.975\n",
      "Acurácia para a resolução 24: 0.975\n",
      "Acurácia para a resolução 25: 0.975\n",
      "Acurácia para a resolução 26: 0.975\n",
      "Acurácia para a resolução 27: 0.975\n",
      "Acurácia para a resolução 28: 0.975\n",
      "Acurácia para a resolução 29: 0.975\n",
      "Acurácia para a resolução 30: 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real_e_imag):\n",
    "    #scores = cross_val_score(labels_predict_real_e_imag, X, y_pred, cv=1)\n",
    "    print(\"Acurácia para a resolução {:2}: {}\" .format((i+2), accuracy_score(y_true, y_pred)))#scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Caso de teste: 'merge' da parte Real com Imaginária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este caso de testes não foi possivel de ser concluído devido na falha de tentativas para conseguir calcular a distancia Euclidiana de uma matriz Numpy, como foi mencionado na função eucld().\n",
    "\n",
    "#### TODO: Implementar este caso de testes em um momento futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epita\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:254: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c6960199cc2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msubject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcortar_imagem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimensao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpessoa_fft_shift\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcortar_imagem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimensao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpessoas_fft_shift\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mlabels_predict_merge_real_imag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OK!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-cce2b6d39e44>\u001b[0m in \u001b[0;36mknn\u001b[1;34m(subjects, dataframe, mode)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mlabeled_image_aux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meucld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_image_aux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_image_aux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mlabeless_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meucld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeless_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeless_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_image_aux\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeless_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rimul'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mmse_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeless_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m--> 251\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    252\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    578\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     56\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "dimensoes = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_merge_real_imag = []\n",
    "\n",
    "print(\"Carregando\")\n",
    "for dimensao in dimensoes:\n",
    "    subject = [cortar_imagem(dimensao, i) for i in pessoa_fft_shift]\n",
    "    dataframe = [cortar_imagem(dimensao, i) for i in pessoas_fft_shift]\n",
    "    labels_predict_merge_real_imag.append(knn(subject, dataframe, 'rim'))\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true = [i for i in range(0,40)]\n",
    "\n",
    "#for i, y_pred in enumerate(labels_predict_merge_real_imag):\n",
    " #   print(\"Acurácia para a resolução {:2}: {}\" .format((i+2), accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Caso de teste: Multiplicação da parte Real e Imaginária \n",
    "\n",
    "Coloquei esse teste adicional porque, enquanto tentei resolver o problema de calcular a distancia Euclidiana para o item 4.5, a forma que tratei o problema foi utilizar uma forma diferente, para fins de processamento computacional. Me deparei com um artigo no qual me lembrou a equivalencia entre a distância Euclidiana tradicional com uma variante vetorial dela, D[i,j] = (Xi -Xj)^T(Xi-Xj), onde T é a transposta da matriz. Durante esses testes eu apliquei esta multiplicação e resolvi iniciá-lo para observar o que aconteceria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "dimensoes = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real_mul_imag = []\n",
    "\n",
    "print(\"Carregando\")\n",
    "for dimensao in dimensoes:\n",
    "    subject = [cortar_imagem(dimensao, i) for i in pessoa_fft_shift]\n",
    "    dataframe = [cortar_imagem(dimensao, i) for i in pessoas_fft_shift]\n",
    "    labels_predict_real_mul_imag.append(knn(subject, dataframe, 'rimul'))\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para a resolução  2: 0.925\n",
      "Acurácia para a resolução  3: 0.975\n",
      "Acurácia para a resolução  4: 0.975\n",
      "Acurácia para a resolução  5: 0.95\n",
      "Acurácia para a resolução  6: 0.975\n",
      "Acurácia para a resolução  7: 0.975\n",
      "Acurácia para a resolução  8: 0.95\n",
      "Acurácia para a resolução  9: 0.95\n",
      "Acurácia para a resolução 10: 0.95\n",
      "Acurácia para a resolução 11: 0.95\n",
      "Acurácia para a resolução 12: 0.95\n",
      "Acurácia para a resolução 13: 0.95\n",
      "Acurácia para a resolução 14: 0.95\n",
      "Acurácia para a resolução 15: 0.95\n",
      "Acurácia para a resolução 16: 0.95\n",
      "Acurácia para a resolução 17: 0.95\n",
      "Acurácia para a resolução 18: 0.95\n",
      "Acurácia para a resolução 19: 0.95\n",
      "Acurácia para a resolução 20: 0.95\n",
      "Acurácia para a resolução 21: 0.95\n",
      "Acurácia para a resolução 22: 0.95\n",
      "Acurácia para a resolução 23: 0.95\n",
      "Acurácia para a resolução 24: 0.95\n",
      "Acurácia para a resolução 25: 0.975\n",
      "Acurácia para a resolução 26: 0.975\n",
      "Acurácia para a resolução 27: 0.975\n",
      "Acurácia para a resolução 28: 0.975\n",
      "Acurácia para a resolução 29: 0.975\n",
      "Acurácia para a resolução 30: 0.975\n"
     ]
    }
   ],
   "source": [
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real_mul_imag):\n",
    "    print(\"Acurácia para a resolução {:2}: {}\" .format((i+2), accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusão\n",
    "\n",
    "Acredito que os resultados obtidos do projeto foram satisfatíveis, com excessão do item 4.5 que se encontra não realizado e do Cross Validation, que não me ficou claro como eu faria um train_test_split de uma imagem para separar em X e y, algo que poderia ter sido resolvido anteriormente com o professor. A disciplina de Sinais e Sistemas, além de sua proposta principal, também pôde auxiliar no aumento com relação ao conhecimento que obtive através da disciplina de Inteligência Artificial e programação, assim, pude a colocar em prática novamente estas áreas, neste caso, utilizando imagens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fourier](870x489_joseph_fourier.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
